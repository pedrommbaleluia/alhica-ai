#!/usr/bin/env python3
"""
Alhica AI - Sistema Completo de Analytics e Dashboard
Sistema avan√ßado para an√°lise de dados, m√©tricas e visualiza√ß√µes em tempo real

Copyright (c) 2024 Alhica AI Team
"""

import os
import json
import logging
import sqlite3
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.io as pio
from flask import Flask, render_template_string, jsonify, request
import threading
import time
from concurrent.futures import ThreadPoolExecutor
import psutil
import redis

# Configura√ß√£o de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/var/log/alhica-ai/analytics.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class MetricData:
    """Dados de uma m√©trica espec√≠fica"""
    name: str
    value: Union[int, float, str]
    timestamp: datetime
    category: str
    metadata: Dict[str, Any]
    unit: str = ""
    trend: Optional[str] = None  # up, down, stable

@dataclass
class AnalyticsReport:
    """Relat√≥rio de analytics"""
    report_id: str
    title: str
    description: str
    generated_at: datetime
    data: Dict[str, Any]
    charts: List[Dict[str, Any]]
    insights: List[str]
    recommendations: List[str]

class AnalyticsDashboardSystem:
    """Sistema completo de analytics e dashboard"""
    
    def __init__(self, db_path: str = "/opt/alhica-ai/data/analytics.db"):
        self.db_path = db_path
        self.redis_client = None
        self.metrics_cache = {}
        self.real_time_data = defaultdict(list)
        self.dashboard_app = None
        
        # Configurar Redis se dispon√≠vel
        self._setup_redis()
        
        # Configurar base de dados
        self._setup_database()
        
        # Inicializar coleta de m√©tricas
        self.metrics_collector = MetricsCollector(self)
        
        # Configurar dashboard web
        self._setup_dashboard()
        
        logger.info("üìä Sistema de analytics inicializado")
    
    def _setup_redis(self):
        """Configurar Redis para cache de m√©tricas"""
        try:
            self.redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
            self.redis_client.ping()
            logger.info("Redis conectado para cache de m√©tricas")
        except Exception as e:
            logger.warning(f"Redis n√£o dispon√≠vel: {e}")
            self.redis_client = None
    
    def _setup_database(self):
        """Configurar base de dados para analytics"""
        try:
            os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
            
            with sqlite3.connect(self.db_path) as conn:
                # Tabela de m√©tricas
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS metrics (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        name TEXT NOT NULL,
                        value TEXT NOT NULL,
                        category TEXT NOT NULL,
                        unit TEXT DEFAULT '',
                        metadata TEXT DEFAULT '{}',
                        timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
                    )
                ''')
                
                # Tabela de eventos do sistema
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS system_events (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        event_type TEXT NOT NULL,
                        event_data TEXT NOT NULL,
                        severity TEXT DEFAULT 'info',
                        source TEXT NOT NULL,
                        timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
                    )
                ''')
                
                # Tabela de performance de modelos
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS model_performance (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        model_name TEXT NOT NULL,
                        metric_name TEXT NOT NULL,
                        metric_value REAL NOT NULL,
                        execution_time REAL,
                        input_tokens INTEGER,
                        output_tokens INTEGER,
                        timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
                    )
                ''')
                
                # Tabela de uso de recursos
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS resource_usage (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        resource_type TEXT NOT NULL,
                        usage_value REAL NOT NULL,
                        max_value REAL,
                        unit TEXT DEFAULT '',
                        hostname TEXT DEFAULT 'localhost',
                        timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
                    )
                ''')
                
                # Tabela de sess√µes de utilizador
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS user_sessions (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        user_id TEXT NOT NULL,
                        session_id TEXT NOT NULL,
                        session_duration INTEGER,
                        commands_executed INTEGER DEFAULT 0,
                        success_rate REAL DEFAULT 0.0,
                        start_time DATETIME DEFAULT CURRENT_TIMESTAMP,
                        end_time DATETIME
                    )
                ''')
                
                # Tabela de relat√≥rios
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS analytics_reports (
                        report_id TEXT PRIMARY KEY,
                        title TEXT NOT NULL,
                        description TEXT,
                        report_data TEXT NOT NULL,
                        generated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                        report_type TEXT DEFAULT 'general'
                    )
                ''')
                
                # √çndices para performance
                conn.execute('CREATE INDEX IF NOT EXISTS idx_metrics_timestamp ON metrics(timestamp)')
                conn.execute('CREATE INDEX IF NOT EXISTS idx_metrics_category ON metrics(category)')
                conn.execute('CREATE INDEX IF NOT EXISTS idx_events_timestamp ON system_events(timestamp)')
                conn.execute('CREATE INDEX IF NOT EXISTS idx_model_performance_timestamp ON model_performance(timestamp)')
                conn.execute('CREATE INDEX IF NOT EXISTS idx_resource_usage_timestamp ON resource_usage(timestamp)')
                
                conn.commit()
                
        except Exception as e:
            logger.error(f"Erro ao configurar base de dados: {e}")
    
    def _setup_dashboard(self):
        """Configurar dashboard web"""
        self.dashboard_app = Flask(__name__)
        
        @self.dashboard_app.route('/')
        def dashboard_home():
            return render_template_string(self._get_dashboard_template())
        
        @self.dashboard_app.route('/api/metrics')
        def api_metrics():
            metrics = self.get_current_metrics()
            return jsonify(metrics)
        
        @self.dashboard_app.route('/api/charts/<chart_type>')
        def api_charts(chart_type):
            chart_data = self.generate_chart(chart_type)
            return jsonify(chart_data)
        
        @self.dashboard_app.route('/api/reports')
        def api_reports():
            reports = self.get_recent_reports()
            return jsonify(reports)
        
        @self.dashboard_app.route('/api/realtime')
        def api_realtime():
            data = self.get_realtime_data()
            return jsonify(data)
    
    def record_metric(self, name: str, value: Union[int, float, str], 
                     category: str, unit: str = "", metadata: Dict[str, Any] = None):
        """Registar m√©trica"""
        metric = MetricData(
            name=name,
            value=value,
            timestamp=datetime.now(),
            category=category,
            metadata=metadata or {},
            unit=unit
        )
        
        # Salvar na base de dados
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute('''
                    INSERT INTO metrics (name, value, category, unit, metadata)
                    VALUES (?, ?, ?, ?, ?)
                ''', (
                    metric.name,
                    json.dumps(metric.value),
                    metric.category,
                    metric.unit,
                    json.dumps(metric.metadata)
                ))
                conn.commit()
        except Exception as e:
            logger.error(f"Erro ao salvar m√©trica: {e}")
        
        # Cache em Redis se dispon√≠vel
        if self.redis_client:
            try:
                cache_key = f"metric:{category}:{name}"
                self.redis_client.setex(cache_key, 3600, json.dumps(asdict(metric), default=str))
            except Exception as e:
                logger.warning(f"Erro ao cachear m√©trica: {e}")
        
        # Adicionar aos dados em tempo real
        self.real_time_data[category].append(metric)
        
        # Manter apenas √∫ltimos 100 pontos por categoria
        if len(self.real_time_data[category]) > 100:
            self.real_time_data[category] = self.real_time_data[category][-100:]
    
    def record_system_event(self, event_type: str, event_data: Dict[str, Any], 
                           severity: str = "info", source: str = "system"):
        """Registar evento do sistema"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute('''
                    INSERT INTO system_events (event_type, event_data, severity, source)
                    VALUES (?, ?, ?, ?)
                ''', (event_type, json.dumps(event_data), severity, source))
                conn.commit()
        except Exception as e:
            logger.error(f"Erro ao registar evento: {e}")
    
    def record_model_performance(self, model_name: str, metric_name: str, 
                                metric_value: float, execution_time: float = None,
                                input_tokens: int = None, output_tokens: int = None):
        """Registar performance de modelo"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute('''
                    INSERT INTO model_performance 
                    (model_name, metric_name, metric_value, execution_time, input_tokens, output_tokens)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (model_name, metric_name, metric_value, execution_time, input_tokens, output_tokens))
                conn.commit()
        except Exception as e:
            logger.error(f"Erro ao registar performance: {e}")
    
    def record_resource_usage(self, resource_type: str, usage_value: float, 
                             max_value: float = None, unit: str = "", hostname: str = "localhost"):
        """Registar uso de recursos"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute('''
                    INSERT INTO resource_usage (resource_type, usage_value, max_value, unit, hostname)
                    VALUES (?, ?, ?, ?, ?)
                ''', (resource_type, usage_value, max_value, unit, hostname))
                conn.commit()
        except Exception as e:
            logger.error(f"Erro ao registar uso de recursos: {e}")
    
    def get_current_metrics(self) -> Dict[str, Any]:
        """Obter m√©tricas atuais"""
        metrics = {}
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # M√©tricas por categoria
                cursor.execute('''
                    SELECT category, COUNT(*) as count, 
                           AVG(CASE WHEN value REGEXP '^[0-9]+\.?[0-9]*$' THEN CAST(value as REAL) END) as avg_value
                    FROM metrics 
                    WHERE timestamp > datetime('now', '-1 hour')
                    GROUP BY category
                ''')
                
                categories = {}
                for row in cursor.fetchall():
                    categories[row[0]] = {
                        'count': row[1],
                        'average': round(row[2], 2) if row[2] else 0
                    }
                
                metrics['categories'] = categories
                
                # Eventos recentes
                cursor.execute('''
                    SELECT event_type, COUNT(*) as count
                    FROM system_events 
                    WHERE timestamp > datetime('now', '-1 hour')
                    GROUP BY event_type
                    ORDER BY count DESC
                    LIMIT 10
                ''')
                
                events = dict(cursor.fetchall())
                metrics['recent_events'] = events
                
                # Performance dos modelos
                cursor.execute('''
                    SELECT model_name, AVG(metric_value) as avg_performance, AVG(execution_time) as avg_time
                    FROM model_performance 
                    WHERE timestamp > datetime('now', '-1 hour')
                    GROUP BY model_name
                ''')
                
                models = {}
                for row in cursor.fetchall():
                    models[row[0]] = {
                        'performance': round(row[1], 3) if row[1] else 0,
                        'avg_time': round(row[2], 3) if row[2] else 0
                    }
                
                metrics['model_performance'] = models
                
        except Exception as e:
            logger.error(f"Erro ao obter m√©tricas: {e}")
        
        return metrics
    
    def generate_chart(self, chart_type: str) -> Dict[str, Any]:
        """Gerar dados para gr√°fico"""
        try:
            if chart_type == "resource_usage":
                return self._generate_resource_usage_chart()
            elif chart_type == "model_performance":
                return self._generate_model_performance_chart()
            elif chart_type == "user_activity":
                return self._generate_user_activity_chart()
            elif chart_type == "system_events":
                return self._generate_system_events_chart()
            elif chart_type == "realtime_metrics":
                return self._generate_realtime_metrics_chart()
            else:
                return {"error": f"Tipo de gr√°fico n√£o suportado: {chart_type}"}
        except Exception as e:
            logger.error(f"Erro ao gerar gr√°fico {chart_type}: {e}")
            return {"error": str(e)}
    
    def _generate_resource_usage_chart(self) -> Dict[str, Any]:
        """Gerar gr√°fico de uso de recursos"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                df = pd.read_sql_query('''
                    SELECT resource_type, usage_value, timestamp
                    FROM resource_usage 
                    WHERE timestamp > datetime('now', '-24 hours')
                    ORDER BY timestamp
                ''', conn)
            
            if df.empty:
                return {"data": [], "layout": {}, "message": "Sem dados de recursos"}
            
            fig = px.line(df, x='timestamp', y='usage_value', color='resource_type',
                         title='Uso de Recursos (24h)')
            
            return {
                "data": fig.data,
                "layout": fig.layout,
                "type": "line"
            }
            
        except Exception as e:
            logger.error(f"Erro ao gerar gr√°fico de recursos: {e}")
            return {"error": str(e)}
    
    def _generate_model_performance_chart(self) -> Dict[str, Any]:
        """Gerar gr√°fico de performance dos modelos"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                df = pd.read_sql_query('''
                    SELECT model_name, AVG(metric_value) as avg_performance, 
                           AVG(execution_time) as avg_time, COUNT(*) as requests
                    FROM model_performance 
                    WHERE timestamp > datetime('now', '-24 hours')
                    GROUP BY model_name
                ''', conn)
            
            if df.empty:
                return {"data": [], "layout": {}, "message": "Sem dados de performance"}
            
            fig = make_subplots(
                rows=2, cols=1,
                subplot_titles=('Performance M√©dia', 'Tempo de Execu√ß√£o'),
                specs=[[{"secondary_y": False}], [{"secondary_y": False}]]
            )
            
            fig.add_trace(
                go.Bar(x=df['model_name'], y=df['avg_performance'], name='Performance'),
                row=1, col=1
            )
            
            fig.add_trace(
                go.Bar(x=df['model_name'], y=df['avg_time'], name='Tempo (s)'),
                row=2, col=1
            )
            
            fig.update_layout(title_text="Performance dos Modelos IA")
            
            return {
                "data": fig.data,
                "layout": fig.layout,
                "type": "subplot"
            }
            
        except Exception as e:
            logger.error(f"Erro ao gerar gr√°fico de performance: {e}")
            return {"error": str(e)}
    
    def _generate_user_activity_chart(self) -> Dict[str, Any]:
        """Gerar gr√°fico de atividade de utilizadores"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                df = pd.read_sql_query('''
                    SELECT DATE(start_time) as date, COUNT(*) as sessions,
                           AVG(commands_executed) as avg_commands,
                           AVG(success_rate) as avg_success_rate
                    FROM user_sessions 
                    WHERE start_time > datetime('now', '-30 days')
                    GROUP BY DATE(start_time)
                    ORDER BY date
                ''', conn)
            
            if df.empty:
                return {"data": [], "layout": {}, "message": "Sem dados de utilizadores"}
            
            fig = make_subplots(
                rows=2, cols=1,
                subplot_titles=('Sess√µes por Dia', 'Taxa de Sucesso'),
                specs=[[{"secondary_y": True}], [{"secondary_y": False}]]
            )
            
            fig.add_trace(
                go.Scatter(x=df['date'], y=df['sessions'], name='Sess√µes', mode='lines+markers'),
                row=1, col=1
            )
            
            fig.add_trace(
                go.Scatter(x=df['date'], y=df['avg_commands'], name='Comandos M√©dios', mode='lines'),
                row=1, col=1, secondary_y=True
            )
            
            fig.add_trace(
                go.Bar(x=df['date'], y=df['avg_success_rate'], name='Taxa de Sucesso'),
                row=2, col=1
            )
            
            fig.update_layout(title_text="Atividade de Utilizadores (30 dias)")
            
            return {
                "data": fig.data,
                "layout": fig.layout,
                "type": "subplot"
            }
            
        except Exception as e:
            logger.error(f"Erro ao gerar gr√°fico de utilizadores: {e}")
            return {"error": str(e)}
    
    def _generate_system_events_chart(self) -> Dict[str, Any]:
        """Gerar gr√°fico de eventos do sistema"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                df = pd.read_sql_query('''
                    SELECT event_type, severity, COUNT(*) as count
                    FROM system_events 
                    WHERE timestamp > datetime('now', '-24 hours')
                    GROUP BY event_type, severity
                    ORDER BY count DESC
                ''', conn)
            
            if df.empty:
                return {"data": [], "layout": {}, "message": "Sem eventos do sistema"}
            
            fig = px.sunburst(df, path=['severity', 'event_type'], values='count',
                             title='Eventos do Sistema por Severidade (24h)')
            
            return {
                "data": fig.data,
                "layout": fig.layout,
                "type": "sunburst"
            }
            
        except Exception as e:
            logger.error(f"Erro ao gerar gr√°fico de eventos: {e}")
            return {"error": str(e)}
    
    def _generate_realtime_metrics_chart(self) -> Dict[str, Any]:
        """Gerar gr√°fico de m√©tricas em tempo real"""
        try:
            data = []
            
            for category, metrics in self.real_time_data.items():
                if not metrics:
                    continue
                
                timestamps = [m.timestamp for m in metrics[-20:]]  # √öltimos 20 pontos
                values = []
                
                for m in metrics[-20:]:
                    try:
                        # Tentar converter para n√∫mero
                        if isinstance(m.value, (int, float)):
                            values.append(m.value)
                        else:
                            values.append(float(m.value))
                    except (ValueError, TypeError):
                        values.append(0)
                
                if values:
                    data.append({
                        'x': timestamps,
                        'y': values,
                        'name': category,
                        'type': 'scatter',
                        'mode': 'lines+markers'
                    })
            
            layout = {
                'title': 'M√©tricas em Tempo Real',
                'xaxis': {'title': 'Tempo'},
                'yaxis': {'title': 'Valor'},
                'showlegend': True
            }
            
            return {
                "data": data,
                "layout": layout,
                "type": "realtime"
            }
            
        except Exception as e:
            logger.error(f"Erro ao gerar gr√°fico em tempo real: {e}")
            return {"error": str(e)}
    
    def generate_report(self, report_type: str = "general", 
                       start_date: datetime = None, end_date: datetime = None) -> AnalyticsReport:
        """Gerar relat√≥rio de analytics"""
        if not start_date:
            start_date = datetime.now() - timedelta(days=7)
        if not end_date:
            end_date = datetime.now()
        
        report_id = f"report_{int(datetime.now().timestamp())}"
        
        try:
            # Coletar dados para o relat√≥rio
            report_data = self._collect_report_data(start_date, end_date)
            
            # Gerar insights
            insights = self._generate_insights(report_data)
            
            # Gerar recomenda√ß√µes
            recommendations = self._generate_recommendations(report_data)
            
            # Gerar gr√°ficos
            charts = [
                self.generate_chart("resource_usage"),
                self.generate_chart("model_performance"),
                self.generate_chart("user_activity"),
                self.generate_chart("system_events")
            ]
            
            report = AnalyticsReport(
                report_id=report_id,
                title=f"Relat√≥rio de Analytics - {report_type.title()}",
                description=f"Relat√≥rio gerado para o per√≠odo de {start_date.date()} a {end_date.date()}",
                generated_at=datetime.now(),
                data=report_data,
                charts=charts,
                insights=insights,
                recommendations=recommendations
            )
            
            # Salvar relat√≥rio
            self._save_report(report)
            
            return report
            
        except Exception as e:
            logger.error(f"Erro ao gerar relat√≥rio: {e}")
            raise
    
    def _collect_report_data(self, start_date: datetime, end_date: datetime) -> Dict[str, Any]:
        """Coletar dados para relat√≥rio"""
        data = {}
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # Estat√≠sticas gerais
                cursor.execute('''
                    SELECT COUNT(*) FROM metrics 
                    WHERE timestamp BETWEEN ? AND ?
                ''', (start_date.isoformat(), end_date.isoformat()))
                data['total_metrics'] = cursor.fetchone()[0]
                
                cursor.execute('''
                    SELECT COUNT(*) FROM system_events 
                    WHERE timestamp BETWEEN ? AND ?
                ''', (start_date.isoformat(), end_date.isoformat()))
                data['total_events'] = cursor.fetchone()[0]
                
                cursor.execute('''
                    SELECT COUNT(*) FROM user_sessions 
                    WHERE start_time BETWEEN ? AND ?
                ''', (start_date.isoformat(), end_date.isoformat()))
                data['total_sessions'] = cursor.fetchone()[0]
                
                # Performance dos modelos
                cursor.execute('''
                    SELECT model_name, AVG(metric_value), AVG(execution_time), COUNT(*)
                    FROM model_performance 
                    WHERE timestamp BETWEEN ? AND ?
                    GROUP BY model_name
                ''', (start_date.isoformat(), end_date.isoformat()))
                
                model_stats = {}
                for row in cursor.fetchall():
                    model_stats[row[0]] = {
                        'avg_performance': round(row[1], 3) if row[1] else 0,
                        'avg_execution_time': round(row[2], 3) if row[2] else 0,
                        'total_requests': row[3]
                    }
                data['model_statistics'] = model_stats
                
                # Uso de recursos
                cursor.execute('''
                    SELECT resource_type, AVG(usage_value), MAX(usage_value), COUNT(*)
                    FROM resource_usage 
                    WHERE timestamp BETWEEN ? AND ?
                    GROUP BY resource_type
                ''', (start_date.isoformat(), end_date.isoformat()))
                
                resource_stats = {}
                for row in cursor.fetchall():
                    resource_stats[row[0]] = {
                        'avg_usage': round(row[1], 2) if row[1] else 0,
                        'max_usage': round(row[2], 2) if row[2] else 0,
                        'measurements': row[3]
                    }
                data['resource_statistics'] = resource_stats
                
        except Exception as e:
            logger.error(f"Erro ao coletar dados do relat√≥rio: {e}")
        
        return data
    
    def _generate_insights(self, report_data: Dict[str, Any]) -> List[str]:
        """Gerar insights baseados nos dados"""
        insights = []
        
        try:
            # Insights sobre modelos
            if 'model_statistics' in report_data:
                model_stats = report_data['model_statistics']
                
                if model_stats:
                    # Modelo mais usado
                    most_used = max(model_stats.items(), key=lambda x: x[1]['total_requests'])
                    insights.append(f"O modelo mais utilizado foi {most_used[0]} com {most_used[1]['total_requests']} requisi√ß√µes")
                    
                    # Modelo mais r√°pido
                    fastest = min(model_stats.items(), key=lambda x: x[1]['avg_execution_time'])
                    insights.append(f"O modelo mais r√°pido foi {fastest[0]} com tempo m√©dio de {fastest[1]['avg_execution_time']}s")
            
            # Insights sobre recursos
            if 'resource_statistics' in report_data:
                resource_stats = report_data['resource_statistics']
                
                for resource, stats in resource_stats.items():
                    if stats['max_usage'] > stats['avg_usage'] * 1.5:
                        insights.append(f"Picos de uso detectados em {resource}: m√°ximo {stats['max_usage']}% vs m√©dia {stats['avg_usage']}%")
            
            # Insights sobre atividade
            if report_data.get('total_sessions', 0) > 0:
                insights.append(f"Total de {report_data['total_sessions']} sess√µes de utilizador registadas")
            
            if report_data.get('total_events', 0) > 0:
                insights.append(f"Sistema gerou {report_data['total_events']} eventos durante o per√≠odo")
            
        except Exception as e:
            logger.error(f"Erro ao gerar insights: {e}")
        
        return insights
    
    def _generate_recommendations(self, report_data: Dict[str, Any]) -> List[str]:
        """Gerar recomenda√ß√µes baseadas nos dados"""
        recommendations = []
        
        try:
            # Recomenda√ß√µes sobre recursos
            if 'resource_statistics' in report_data:
                resource_stats = report_data['resource_statistics']
                
                for resource, stats in resource_stats.items():
                    if stats['avg_usage'] > 80:
                        recommendations.append(f"Considere aumentar recursos de {resource} - uso m√©dio de {stats['avg_usage']}%")
                    elif stats['avg_usage'] < 20:
                        recommendations.append(f"Recursos de {resource} subutilizados - considere otimiza√ß√£o")
            
            # Recomenda√ß√µes sobre modelos
            if 'model_statistics' in report_data:
                model_stats = report_data['model_statistics']
                
                slow_models = [name for name, stats in model_stats.items() if stats['avg_execution_time'] > 5.0]
                if slow_models:
                    recommendations.append(f"Modelos com performance lenta detectados: {', '.join(slow_models)} - considere otimiza√ß√£o")
            
            # Recomenda√ß√µes gerais
            if report_data.get('total_events', 0) > 1000:
                recommendations.append("Alto volume de eventos detectado - considere implementar filtros ou agrega√ß√£o")
            
            if not report_data.get('total_sessions', 0):
                recommendations.append("Nenhuma sess√£o de utilizador detectada - verificar conectividade e logs")
            
        except Exception as e:
            logger.error(f"Erro ao gerar recomenda√ß√µes: {e}")
        
        return recommendations
    
    def _save_report(self, report: AnalyticsReport):
        """Salvar relat√≥rio na base de dados"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute('''
                    INSERT INTO analytics_reports (report_id, title, description, report_data)
                    VALUES (?, ?, ?, ?)
                ''', (
                    report.report_id,
                    report.title,
                    report.description,
                    json.dumps(asdict(report), default=str)
                ))
                conn.commit()
        except Exception as e:
            logger.error(f"Erro ao salvar relat√≥rio: {e}")
    
    def get_recent_reports(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Obter relat√≥rios recentes"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    SELECT report_id, title, description, generated_at
                    FROM analytics_reports 
                    ORDER BY generated_at DESC 
                    LIMIT ?
                ''', (limit,))
                
                reports = []
                for row in cursor.fetchall():
                    reports.append({
                        'report_id': row[0],
                        'title': row[1],
                        'description': row[2],
                        'generated_at': row[3]
                    })
                
                return reports
                
        except Exception as e:
            logger.error(f"Erro ao obter relat√≥rios: {e}")
            return []
    
    def get_realtime_data(self) -> Dict[str, Any]:
        """Obter dados em tempo real"""
        data = {}
        
        # M√©tricas em tempo real
        for category, metrics in self.real_time_data.items():
            if metrics:
                latest = metrics[-1]
                data[category] = {
                    'value': latest.value,
                    'timestamp': latest.timestamp.isoformat(),
                    'unit': latest.unit
                }
        
        # Estat√≠sticas do sistema
        data['system'] = {
            'cpu_percent': psutil.cpu_percent(),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_percent': psutil.disk_usage('/').percent,
            'active_sessions': len(self.real_time_data),
            'timestamp': datetime.now().isoformat()
        }
        
        return data
    
    def _get_dashboard_template(self) -> str:
        """Template HTML para dashboard"""
        return '''
<!DOCTYPE html>
<html>
<head>
    <title>Alhica AI - Analytics Dashboard</title>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <style>
        body { font-family: Arial, sans-serif; margin: 0; padding: 20px; background: #f5f5f5; }
        .header { background: #2c3e50; color: white; padding: 20px; margin: -20px -20px 20px -20px; }
        .metrics-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin-bottom: 30px; }
        .metric-card { background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
        .metric-value { font-size: 2em; font-weight: bold; color: #3498db; }
        .metric-label { color: #7f8c8d; margin-top: 5px; }
        .chart-container { background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin-bottom: 20px; }
        .realtime-indicator { display: inline-block; width: 10px; height: 10px; background: #2ecc71; border-radius: 50%; margin-right: 5px; animation: blink 2s infinite; }
        @keyframes blink { 0%, 50% { opacity: 1; } 51%, 100% { opacity: 0.3; } }
    </style>
</head>
<body>
    <div class="header">
        <h1>üöÄ Alhica AI - Analytics Dashboard</h1>
        <p><span class="realtime-indicator"></span>Monitoriza√ß√£o em Tempo Real</p>
    </div>
    
    <div class="metrics-grid" id="metricsGrid">
        <!-- M√©tricas ser√£o carregadas aqui -->
    </div>
    
    <div class="chart-container">
        <h3>üìä Uso de Recursos</h3>
        <div id="resourceChart"></div>
    </div>
    
    <div class="chart-container">
        <h3>ü§ñ Performance dos Modelos IA</h3>
        <div id="modelChart"></div>
    </div>
    
    <div class="chart-container">
        <h3>üë• Atividade de Utilizadores</h3>
        <div id="userChart"></div>
    </div>
    
    <div class="chart-container">
        <h3>‚ö° M√©tricas em Tempo Real</h3>
        <div id="realtimeChart"></div>
    </div>

    <script>
        function loadMetrics() {
            $.get('/api/metrics', function(data) {
                updateMetricsGrid(data);
            });
        }
        
        function updateMetricsGrid(data) {
            let html = '';
            
            // M√©tricas de categorias
            if (data.categories) {
                for (let category in data.categories) {
                    html += `
                        <div class="metric-card">
                            <div class="metric-value">${data.categories[category].count}</div>
                            <div class="metric-label">${category} (√∫ltima hora)</div>
                        </div>
                    `;
                }
            }
            
            // Performance dos modelos
            if (data.model_performance) {
                for (let model in data.model_performance) {
                    html += `
                        <div class="metric-card">
                            <div class="metric-value">${data.model_performance[model].performance}</div>
                            <div class="metric-label">${model} - Performance</div>
                        </div>
                    `;
                }
            }
            
            $('#metricsGrid').html(html);
        }
        
        function loadChart(chartType, containerId) {
            $.get(`/api/charts/${chartType}`, function(data) {
                if (data.error) {
                    $(`#${containerId}`).html(`<p>Erro: ${data.error}</p>`);
                } else if (data.message) {
                    $(`#${containerId}`).html(`<p>${data.message}</p>`);
                } else {
                    Plotly.newPlot(containerId, data.data, data.layout);
                }
            });
        }
        
        function loadRealtimeData() {
            $.get('/api/realtime', function(data) {
                // Atualizar m√©tricas do sistema
                if (data.system) {
                    updateSystemMetrics(data.system);
                }
            });
        }
        
        function updateSystemMetrics(system) {
            let html = `
                <div class="metric-card">
                    <div class="metric-value">${system.cpu_percent}%</div>
                    <div class="metric-label">CPU</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">${system.memory_percent}%</div>
                    <div class="metric-label">Mem√≥ria</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">${system.disk_percent}%</div>
                    <div class="metric-label">Disco</div>
                </div>
            `;
            $('#metricsGrid').prepend(html);
        }
        
        // Carregar dados iniciais
        $(document).ready(function() {
            loadMetrics();
            loadChart('resource_usage', 'resourceChart');
            loadChart('model_performance', 'modelChart');
            loadChart('user_activity', 'userChart');
            loadChart('realtime_metrics', 'realtimeChart');
            
            // Atualizar dados em tempo real
            setInterval(function() {
                loadMetrics();
                loadRealtimeData();
                loadChart('realtime_metrics', 'realtimeChart');
            }, 30000); // A cada 30 segundos
        });
    </script>
</body>
</html>
        '''
    
    def start_dashboard(self, host: str = "0.0.0.0", port: int = 8080):
        """Iniciar dashboard web"""
        def run_dashboard():
            self.dashboard_app.run(host=host, port=port, debug=False)
        
        dashboard_thread = threading.Thread(target=run_dashboard, daemon=True)
        dashboard_thread.start()
        
        logger.info(f"Dashboard iniciado em http://{host}:{port}")

class MetricsCollector:
    """Coletor autom√°tico de m√©tricas do sistema"""
    
    def __init__(self, analytics_system: AnalyticsDashboardSystem):
        self.analytics = analytics_system
        self.running = False
        self.collection_thread = None
        self.collection_interval = 60  # segundos
    
    def start_collection(self):
        """Iniciar coleta autom√°tica de m√©tricas"""
        if self.running:
            return
        
        self.running = True
        self.collection_thread = threading.Thread(target=self._collection_loop, daemon=True)
        self.collection_thread.start()
        
        logger.info("Coleta autom√°tica de m√©tricas iniciada")
    
    def stop_collection(self):
        """Parar coleta de m√©tricas"""
        self.running = False
        if self.collection_thread:
            self.collection_thread.join()
        
        logger.info("Coleta de m√©tricas parada")
    
    def _collection_loop(self):
        """Loop principal de coleta"""
        while self.running:
            try:
                self._collect_system_metrics()
                time.sleep(self.collection_interval)
            except Exception as e:
                logger.error(f"Erro na coleta de m√©tricas: {e}")
                time.sleep(self.collection_interval)
    
    def _collect_system_metrics(self):
        """Coletar m√©tricas do sistema"""
        try:
            # CPU
            cpu_percent = psutil.cpu_percent(interval=1)
            self.analytics.record_resource_usage("cpu", cpu_percent, 100, "%")
            
            # Mem√≥ria
            memory = psutil.virtual_memory()
            self.analytics.record_resource_usage("memory", memory.percent, 100, "%")
            
            # Disco
            disk = psutil.disk_usage('/')
            disk_percent = (disk.used / disk.total) * 100
            self.analytics.record_resource_usage("disk", disk_percent, 100, "%")
            
            # Rede
            network = psutil.net_io_counters()
            self.analytics.record_metric("network_bytes_sent", network.bytes_sent, "network", "bytes")
            self.analytics.record_metric("network_bytes_recv", network.bytes_recv, "network", "bytes")
            
            # Processos
            process_count = len(psutil.pids())
            self.analytics.record_metric("process_count", process_count, "system", "count")
            
        except Exception as e:
            logger.error(f"Erro ao coletar m√©tricas do sistema: {e}")

def main():
    """Fun√ß√£o principal para teste"""
    analytics = AnalyticsDashboardSystem()
    
    # Iniciar coleta de m√©tricas
    analytics.metrics_collector.start_collection()
    
    # Registar algumas m√©tricas de teste
    analytics.record_metric("test_metric", 42, "test", "units")
    analytics.record_model_performance("qwen", "accuracy", 0.95, 2.3, 100, 50)
    analytics.record_system_event("test_event", {"message": "Sistema iniciado"}, "info", "test")
    
    # Gerar relat√≥rio
    report = analytics.generate_report("test")
    print(f"Relat√≥rio gerado: {report.report_id}")
    print(f"Insights: {len(report.insights)}")
    print(f"Recomenda√ß√µes: {len(report.recommendations)}")
    
    # Iniciar dashboard
    analytics.start_dashboard(port=8080)
    
    print("Analytics dashboard iniciado em http://localhost:8080")
    print("Pressione Ctrl+C para parar...")
    
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        analytics.metrics_collector.stop_collection()
        print("Sistema parado")

if __name__ == "__main__":
    main()

